{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\llm-rag\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import main\n",
    "from pinecone import Pinecone\n",
    "from openai import OpenAI\n",
    "import os\n",
    "main.load_dotenv()\n",
    "PINECONE_API = os.getenv(\"pineconeapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to convert pdf to txt file for ease of use\n",
    "def convert_pdf2txt(filepath: str = \"sample_data.pdf\"):\n",
    "    content = PyPDF2.PdfReader(filepath)\n",
    "    text = \"\"\n",
    "    for i in range(0, len(content.pages)):\n",
    "        text = text + content.pages[i].extract_text()\n",
    "    with open(\"sample_data.txt\", \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "\n",
    "# pinecone, hf and openai init\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "pc = Pinecone(api_key=PINECONE_API)\n",
    "index_hf = pc.Index(\"rag-llm\")\n",
    "index_openai = pc.Index(\"rag-llm-openai\")\n",
    "\n",
    "\n",
    "# code for embeddings using hf\n",
    "def create_database_hf(file_path=\"sample_data.txt\"):\n",
    "    docs = TextLoader(file_path).load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    content = [splits[i].page_content for i in range(0, len(splits))]\n",
    "\n",
    "    vectors = []\n",
    "    for i in range(0, len(splits)):\n",
    "        vector = {\n",
    "            \"id\": str(i),\n",
    "            \"values\": model.encode(splits[i].page_content),\n",
    "            \"metadata\": {\"content\": content[i]},\n",
    "        }\n",
    "        vectors.append(vector)\n",
    "    index_hf.upsert(vectors=vectors)\n",
    "    return index_hf, content\n",
    "\n",
    "\n",
    "# for embedddings using openai\n",
    "def create_database_openai(file_path=\"sample_data.txt\", index=\"rag-llm\"):\n",
    "    docs = TextLoader(\"sample_data.txt\").load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    content = [splits[i].page_content for i in range(0, len(splits))]\n",
    "    embeddings = client.embeddings.create(model=\"text-embedding-ada-002\", input=content)\n",
    "    vectors = []\n",
    "    for i in range(0, len(splits)):\n",
    "        vector = {\n",
    "            \"id\": str(i),\n",
    "            \"values\": embeddings.data[i].embedding,\n",
    "            \"metadata\": {\"content\": content[i]},\n",
    "        }\n",
    "        vectors.append(vector)\n",
    "    index_openai.upsert(vectors=vectors)\n",
    "    return index, content\n",
    "\n",
    "\n",
    "def find_context(prompt: str, method=\"openai\", top_k=2):\n",
    "    if method == \"openai\":\n",
    "        result = client.embeddings.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=prompt,\n",
    "        )\n",
    "        embed = result.data[0].embedding\n",
    "        content = index_openai.query(\n",
    "            vector=embed, top_k=top_k, include_values=False, include_metadata=True\n",
    "        )\n",
    "        if top_k == 1:\n",
    "            return (\n",
    "                content[\"matches\"][0][\"id\"],\n",
    "                content[\"matches\"][0][\"metadata\"][\"content\"],\n",
    "            )\n",
    "        elif top_k > 0:\n",
    "            content_list = []\n",
    "            index_list = []\n",
    "            for i in range(0, top_k):\n",
    "                index_list.append(content[\"matches\"][i][\"id\"])\n",
    "                content_list.append(content[\"matches\"][i][\"metadata\"][\"content\"])\n",
    "            return index_list, content_list\n",
    "    elif method == \"hf\":\n",
    "        embed = model.encode(prompt).tolist()\n",
    "        content = index_hf.query(\n",
    "            vector=embed, top_k=top_k, include_values=False, include_metadata=True\n",
    "        )\n",
    "        if top_k == 1:\n",
    "            return (\n",
    "                content[\"matches\"][0][\"id\"],\n",
    "                content[\"matches\"][0][\"metadata\"][\"content\"],\n",
    "            )\n",
    "        elif top_k > 0:\n",
    "            content_list = []\n",
    "            index_list = []\n",
    "            for i in range(0, top_k):\n",
    "                index_list.append(content[\"matches\"][i][\"id\"])\n",
    "                content_list.append(content[\"matches\"][i][\"metadata\"][\"content\"])\n",
    "            return index_list, content_list\n",
    "    else:\n",
    "        raise ValueError(\"Method can only be hf or openai\")\n",
    "    \n",
    "def QNA(prompt:str,method = \"openai\"):\n",
    "    if(method == \"openai\"):\n",
    "        id, content = find_context(prompt)\n",
    "    elif(method == \"hf\"):\n",
    "        id, content = find_context(prompt,method = \"hf\")\n",
    "    else:\n",
    "        raise ValueError(\"Method can only be hf or openai\")\n",
    "    system_prompt = f\"You are Given two pages from a book called 48 laws of power. Answer the users questions based on the context from these two pages: \\n\\n page 1 : {content[0]} \\n\\n page 2 : {content[1]}\"\n",
    "    user_prompt = prompt\n",
    "    msg = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "              {\"role\": \"user\", \"content\": user_prompt}],\n",
    "    )\n",
    "    return msg.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = QNA(\"Can you give me an example from history where the enemy was crushed totally from the book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One example from history where the enemy was crushed is mentioned on page 2 of the book. It talks about Ivan the Terrible, who waited five years before executing his first major bold move. After facing persecution and banishment, Ivan invited his rival Prince Andrei Shuisky into his room. Despite being underestimated by others, Ivan ordered the guards to seize Prince Andrei and execute him, catching everyone off guard. This swift and bold act secured Ivan's power for decades to come.\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
